Agentic RAG System with MCP, Milvus & Ollama

An enterprise-ready Agentic Retrieval-Augmented Generation (RAG) system that uses multiple AI agents to intelligently retrieve, reason, and answer questions from documents using self-hosted LLMs.

ğŸš€ Features

1. Planner Agent â€“ decides retrieval strategy

2. Execution Agent â€“ calls MCP tools (Milvus, Excel, PDF)

3. Generator Agent â€“ answers using Ollama (local LLM)

4. Critic Agent â€“ validates grounding & prevents hallucinations

5. Supports PDF, TXT, CSV, Excel, DOCX, PPT

6. Milvus vector database

7. MCP (Model Context Protocol) server

ğŸ–¥ï¸ Clean Streamlit UI

Self-hosted

Architecture
 
User
 â†“
Streamlit UI
 â†“
Planner Agent
 â†“
Execution Agent (MCP Client)
 â†“
MCP Server
 â†“
Milvus Vector DB
 â†“
Generator Agent (Ollama)
 â†“
Critic Agent
 â†“
Final Answer


ğŸ§© Tech Stack

Python

Milvus (Vector DB)

Ollama (Self-hosted LLM)

MCP Server

LangChain

Streamlit

Docker

âš™ï¸ Setup Instructions
1ï¸. Start Milvus
docker compose -f docker/milvus.yml up -d

2ï¸. Start MCP Server
uvicorn app.mcp_server.server:app --port 8001

3ï¸. Start Streamlit UI
streamlit run app/ui/streamlit_app.py --server.fileWatcherType none

Key Design Decisions

Agentic orchestration instead of monolithic RAG

Critic agent to reduce hallucinations

Reset vector store per ingestion for clean grounding
